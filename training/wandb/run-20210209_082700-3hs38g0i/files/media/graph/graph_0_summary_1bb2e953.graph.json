{"format": "torch", "nodes": [{"name": "transformer", "id": 140695694516720, "class_name": "CTRLModel(\n  (w): Embedding(246535, 1280)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (h): ModuleList(\n    (0): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (1): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (2): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (3): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (4): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (5): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (6): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (7): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (8): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (9): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (10): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (11): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (12): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (13): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (14): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (15): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (16): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (17): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (18): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (19): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (20): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (21): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (22): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (23): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (24): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (25): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (26): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (27): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (28): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (29): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (30): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (31): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (32): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (33): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (34): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (35): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (36): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (37): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (38): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (39): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (40): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (41): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (42): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (43): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (44): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (45): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (46): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (47): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (layernorm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n)", "parameters": [], "output_shape": [[[[0], [0], [0], [0], [0], [0], [0], [0], 0, [0], [0], 0, 0, 0, 0, 0, 0], [[0], 0, 0, 0, 0, [0], 0, [0], 0, [0], 0, 0, [0], 0, 0]]], "num_parameters": []}, {"name": "lm_head", "id": 140694118085680, "class_name": "Linear(in_features=1280, out_features=246535, bias=True)", "parameters": [], "output_shape": [[16, 64, 246535]], "num_parameters": []}, {"name": "transformer", "id": 140695694516624, "class_name": "CTRLModel(\n  (w): Embedding(246535, 1280)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (h): ModuleList(\n    (0): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (1): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (2): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (3): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (4): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (5): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (6): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (7): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (8): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (9): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (10): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (11): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (12): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (13): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (14): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (15): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (16): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (17): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (18): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (19): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (20): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (21): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (22): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (23): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (24): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (25): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (26): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (27): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (28): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (29): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (30): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (31): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (32): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (33): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (34): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (35): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (36): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (37): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (38): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (39): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (40): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (41): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (42): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (43): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (44): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (45): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (46): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n    (47): EncoderLayer(\n      (multi_head_attention): MultiHeadAttention(\n        (Wq): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wk): Linear(in_features=1280, out_features=1280, bias=True)\n        (Wv): Linear(in_features=1280, out_features=1280, bias=True)\n        (dense): Linear(in_features=1280, out_features=1280, bias=True)\n      )\n      (ffn): Sequential(\n        (0): Linear(in_features=1280, out_features=8192, bias=True)\n        (1): ReLU()\n        (2): Linear(in_features=8192, out_features=1280, bias=True)\n      )\n      (layernorm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (layernorm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (layernorm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n)", "parameters": [], "output_shape": [[[[0], [0], [0], [0], [0], [0], [0], [0], 0, [0], [0], 0, 0, 0, 0, 0, 0], [[0], 0, 0, 0, 0, [0], 0, [0], 0, [0], 0, 0, [0], 0, 0]]], "num_parameters": []}, {"name": "lm_head", "id": 140694118085824, "class_name": "Linear(in_features=1280, out_features=246535, bias=True)", "parameters": [], "output_shape": [[16, 64, 246535]], "num_parameters": []}], "edges": []}